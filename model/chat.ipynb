{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revised Code: PSA Card Grade Prediction with EfficientNet\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import timm  # Install via: pip install timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# --- Configuration ---\n",
    "ACTIVATE_WEIGHTS_TENSOR = False\n",
    "ACTIVATE_CROPPING = False\n",
    "BATCH_SIZE = 64\n",
    "SET_FRAC = 0.7\n",
    "NUM_EPOCHS = 50  # initial training, can adjust later\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# --- Load dataset ---\n",
    "df = pd.read_csv('../scrape/psa_sales_20250222_170248.csv')\n",
    "image_dir = '../scrape/pictures'\n",
    "df['filename'] = df['certNumber'].apply(lambda x: os.path.join(image_dir, f\"cert_{x}.jpg\"))\n",
    "print(f\"Missing images: {len(df[~df['filename'].apply(os.path.exists)])}\")\n",
    "df = df[df['filename'].apply(os.path.exists)]\n",
    "\n",
    "# --- Split into training and validation sets ---\n",
    "train_df = df.sample(frac=SET_FRAC, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "# --- Encode labels ---\n",
    "le = LabelEncoder()\n",
    "le.fit(df['grade'])\n",
    "train_df['label'] = le.transform(train_df['grade'])\n",
    "val_df['label'] = le.transform(val_df['grade'])\n",
    "\n",
    "print(\"Unique grades:\", df['grade'].unique())\n",
    "\n",
    "grade_counts = df['grade'].value_counts().reset_index()\n",
    "grade_counts.columns = ['grade', 'count']\n",
    "grade_counts['percent'] = grade_counts['count'] / len(df) * 100\n",
    "print(grade_counts)\n",
    "\n",
    "# --- Compute class weights (if needed) ---\n",
    "if ACTIVATE_WEIGHTS_TENSOR:\n",
    "    classes = np.unique(train_df['grade'])\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=train_df['grade'])\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# --- Define cropping functions (unchanged) ---\n",
    "def crop_card_for_light_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, otsu_grad = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(otsu_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    height, width = image.shape[:2]\n",
    "    image_area = height * width\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for contour in contours:\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.001 * peri, True)\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        area = w * h\n",
    "        if 0.48 * image_area <= area <= 0.6 * image_area:\n",
    "            return image[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "def crop_card_for_dark_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), -10)\n",
    "    adaptive_binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 3)\n",
    "    edges = cv2.Canny(adaptive_binary, 100, 200)\n",
    "    binarized_grad = 255 - edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    open_binarized_grad = cv2.morphologyEx(binarized_grad, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(open_binarized_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    height, width = image.shape[:2]\n",
    "    image_area = height * width\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if 0.48 * image_area <= area <= 0.7 * image_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            return image[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "def crop_card(image):\n",
    "    cropped = crop_card_for_light_image(image)\n",
    "    if cropped is not None:\n",
    "        return cropped\n",
    "    cropped = crop_card_for_dark_image(image)\n",
    "    if cropped is not None:\n",
    "        return cropped\n",
    "    return image  # Fallback\n",
    "\n",
    "def pad_to_square(image, fill=0, padding_mode=\"constant\"):\n",
    "    w, h = image.size\n",
    "    if w == h:\n",
    "        return image\n",
    "    max_wh = max(w, h)\n",
    "    pad_left = (max_wh - w) // 2\n",
    "    pad_top = (max_wh - h) // 2\n",
    "    pad_right = max_wh - w - pad_left\n",
    "    pad_bottom = max_wh - h - pad_top\n",
    "    padding = (pad_left, pad_top, pad_right, pad_bottom)\n",
    "    return transforms.Pad(padding, fill=fill, padding_mode=padding_mode)(image)\n",
    "\n",
    "# --- Updated transform pipeline with augmentations ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=0)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=0)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def show_sample_images(df, transform):\n",
    "    sample_df = df.sample(5)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for ax, (_, row) in zip(axes, sample_df.iterrows()):\n",
    "        img_path = row['filename']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transform(image)\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample transformed training images:\")\n",
    "show_sample_images(train_df, train_transform)\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class CardDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        if ACTIVATE_CROPPING:\n",
    "            self.failed_crops = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['filename']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if ACTIVATE_CROPPING:\n",
    "            image_np = np.array(image)\n",
    "            cropped_np = crop_card(image_np)\n",
    "            if cropped_np is image_np:\n",
    "                self.failed_crops.append(img_path)\n",
    "            image = Image.fromarray(cropped_np)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = CardDataset(train_df, transform=train_transform)\n",
    "val_dataset = CardDataset(val_df, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "if ACTIVATE_CROPPING:\n",
    "    print(f\"Failed crops in training: {len(train_dataset.failed_crops)}\")\n",
    "    print(f\"Failed crops in validation: {len(val_dataset.failed_crops)}\")\n",
    "\n",
    "# --- Build the model using EfficientNet ---\n",
    "model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "n_features = model.classifier.in_features  # EfficientNet classifier features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(n_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, len(le.classes_))\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Optionally freeze feature extractor for initial training\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# --- Loss, Optimizer, and Scheduler ---\n",
    "if ACTIVATE_WEIGHTS_TENSOR:\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# --- Validation function ---\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "# --- Training function with early stopping ---\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, phase='Initial'):\n",
    "    best_val_loss = float('inf')\n",
    "    patience, patience_counter = 7, 0\n",
    "    scaler = GradScaler()\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(f\"{phase} Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f'best_model_{phase.lower()}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    return history\n",
    "\n",
    "# --- Initial training ---\n",
    "history_initial = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, phase='Initial')\n",
    "\n",
    "# --- Fine-tuning: Unfreeze later layers ---\n",
    "model.load_state_dict(torch.load('best_model_initial.pth'))\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' in name or 'blocks.5' in name or 'blocks.6' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "history_finetune = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, phase='FineTune')\n",
    "\n",
    "# --- Load best fine-tuned model ---\n",
    "model.load_state_dict(torch.load('best_model_finetune.pth'))\n",
    "\n",
    "# --- Visualize training history ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_initial['val_accuracy'] + history_finetune['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_initial['val_loss'] + history_finetune['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Save final model ---\n",
    "torch.save(model.state_dict(), 'card_grader_model_efficientnet.pth')\n",
    "\n",
    "# --- Prediction function ---\n",
    "def predict_grade(img_path, model, le, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    cropped_np = crop_card(image_np)\n",
    "    image = Image.fromarray(cropped_np)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "    return le.inverse_transform([pred.item()])[0]\n",
    "\n",
    "# --- Evaluate final model ---\n",
    "val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "print(f\"Overall Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
