{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm albumentations wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    # Model settings\n",
    "    model_name = 'convnext_large_in22k'\n",
    "    image_size = 384\n",
    "    batch_size = 32\n",
    "    num_epochs = 30\n",
    "    num_folds = 5\n",
    "    \n",
    "    # Training settings\n",
    "    learning_rate = 1e-4\n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 0.01\n",
    "    \n",
    "    # Simplified augmentation settings\n",
    "    train_aug = A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.HorizontalFlip(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    val_aug = A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "class CardDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = cv2.imread(row['filename'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "            \n",
    "        return image, row['label']\n",
    "\n",
    "class GradingModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "        \n",
    "        # Replace classifier\n",
    "        in_features = self.model.get_classifier().in_features\n",
    "        self.model.reset_classifier(0)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(in_features),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x[:, 0]  # Take CLS token for ViT-like models\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_fold(fold, train_df, val_df, config, num_classes):\n",
    "    train_dataset = CardDataset(train_df, config.train_aug)\n",
    "    val_dataset = CardDataset(val_df, config.val_aug)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, \n",
    "                            shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, \n",
    "                          shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = GradingModel(config.model_name, num_classes=num_classes)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                lr=config.learning_rate,\n",
    "                                weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                          T_max=config.num_epochs,\n",
    "                                                          eta_min=config.min_lr)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    best_acc = 0\n",
    "    for epoch in range(config.num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'best_model_fold{fold}.pth')\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Fold {fold}, Epoch {epoch+1}/{config.num_epochs}')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}')\n",
    "        print(f'Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "    return best_acc\n",
    "\n",
    "def main():\n",
    "    wandb.init(project=\"card-grading\")\n",
    "    \n",
    "    config = Config()\n",
    "    df = pd.read_csv('../scrape/psa_sales_20250222_170248.csv')\n",
    "    \n",
    "    # Print class distribution before encoding\n",
    "    print(\"Grade distribution:\")\n",
    "    print(df['grade'].value_counts())\n",
    "    \n",
    "    # Data preparation\n",
    "    le = LabelEncoder()\n",
    "    df['label'] = le.fit_transform(df['grade'])\n",
    "    num_classes = len(le.classes_)\n",
    "    \n",
    "    print(f\"\\nNumber of classes: {num_classes}\")\n",
    "    print(\"Class mapping:\")\n",
    "    for i, grade in enumerate(le.classes_):\n",
    "        print(f\"{grade} -> {i}\")\n",
    "    \n",
    "    # Handle class imbalance warning\n",
    "    if len(df['grade'].unique()) < config.num_folds:\n",
    "        config.num_folds = len(df['grade'].unique())\n",
    "        print(f\"\\nWarning: Reducing number of folds to {config.num_folds} due to limited classes\")\n",
    "    \n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=config.num_folds, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['label'])):\n",
    "        print(f\"\\nTraining Fold {fold + 1}/{config.num_folds}\")\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        # Print split sizes\n",
    "        print(f\"Training set size: {len(train_df)}\")\n",
    "        print(f\"Validation set size: {len(val_df)}\")\n",
    "        \n",
    "        best_acc = train_fold(fold, train_df, val_df, config, num_classes)\n",
    "        fold_scores.append(best_acc)\n",
    "        \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Cross-validation scores: {fold_scores}\")\n",
    "    print(f\"Mean accuracy: {np.mean(fold_scores):.4f}\")\n",
    "    print(f\"Std accuracy: {np.std(fold_scores):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
