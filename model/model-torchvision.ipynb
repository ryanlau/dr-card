{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision opencv-python pandas scikit-learn pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "ACTIVATE_WEIGHTS_TENSOR = 0\n",
    "ACTIVATE_CROPPING = 0\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS_INITIAL = 50\n",
    "EPOCHS_FINE_TUNE = 60\n",
    "DROPOUT_PROB = 0.3  # Lower dropout\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 7  # Increased patience\n",
    "SPLIT_FRAC = 0.7\n",
    "\n",
    "# Set device (assumes GPU like H200 is available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../scrape/psa_sales_20250222_170248.csv')  # Replace with your CSV path\n",
    "image_dir = '../scrape/cropped'  # Replace with your image directory\n",
    "df['filename'] = df['certNumber'].apply(lambda x: os.path.join(image_dir, f\"cert_{x}.jpg\"))\n",
    "\n",
    "# print how many images are missing\n",
    "print(f\"Missing images: {len(df[df['filename'].apply(lambda x: not os.path.exists(x))])}\")\n",
    "\n",
    "# Remove non-existing images\n",
    "df = df[df['filename'].apply(os.path.exists)]\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_df = df.sample(frac=SPLIT_FRAC, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(df['grade'])\n",
    "train_df['label'] = le.transform(train_df['grade'])\n",
    "val_df['label'] = le.transform(val_df['grade'])\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Unique grades in full dataset:\", df['grade'].unique())\n",
    "print(\"Number of unique grades in full dataset:\", df['grade'].nunique())\n",
    "\n",
    "grade_counts = df['grade'].value_counts()\n",
    "\n",
    "# also add percent of total to grade_counts as a new column\n",
    "grade_counts = grade_counts.reset_index()\n",
    "grade_counts.columns = ['grade', 'count']\n",
    "grade_counts['percent'] = grade_counts['count'] / len(df) * 100\n",
    "\n",
    "print(grade_counts)\n",
    "\n",
    "# Compute class weights for imbalance\n",
    "if ACTIVATE_WEIGHTS_TENSOR:\n",
    "    classes = np.unique(train_df['grade'])\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=train_df['grade'])\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define cropping functions inspired by psa_pokemon_cards\n",
    "def crop_card_for_light_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, otsu_grad = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(otsu_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    height, width = image.shape[:2]\n",
    "    image_area = height * width\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for contour in contours:\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.001 * peri, True)\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        area = w * h\n",
    "        if 0.48 * image_area <= area <= 0.6 * image_area:\n",
    "            return image[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "def crop_card_for_dark_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), -10)\n",
    "    adaptive_binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 3)\n",
    "    edges = cv2.Canny(adaptive_binary, 100, 200)\n",
    "    binarized_grad = 255 - edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    open_binarized_grad = cv2.morphologyEx(binarized_grad, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(open_binarized_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    height, width = image.shape[:2]\n",
    "    image_area = height * width\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if 0.48 * image_area <= area <= 0.7 * image_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            return image[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "def crop_card(image):\n",
    "    cropped = crop_card_for_light_image(image)\n",
    "    if cropped is not None:\n",
    "        return cropped\n",
    "    cropped = crop_card_for_dark_image(image)\n",
    "    if cropped is not None:\n",
    "        return cropped\n",
    "    return image  # Fallback to original if cropping fails\n",
    "\n",
    "def pad_to_square(image, fill=0, padding_mode=\"constant\"):\n",
    "    \"\"\"\n",
    "    Pads a rectangular image to a square shape by adding equal padding on the shorter sides.\n",
    "    \"\"\"\n",
    "    w, h = image.size\n",
    "    if w == h:\n",
    "        return image\n",
    "    max_wh = max(w, h)\n",
    "    pad_left = (max_wh - w) // 2\n",
    "    pad_top = (max_wh - h) // 2\n",
    "    pad_right = max_wh - w - pad_left\n",
    "    pad_bottom = max_wh - h - pad_top\n",
    "    padding = (pad_left, pad_top, pad_right, pad_bottom)\n",
    "    return transforms.Pad(padding, fill=fill, padding_mode=padding_mode)(image)\n",
    "\n",
    "# Updated transform pipeline: pad first, then resize to 224.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=0)),  # Pad to square so the entire card is visible\n",
    "    transforms.Resize(224),  # Resize the square image to 224×224 without cropping\n",
    "    transforms.ToTensor(),\n",
    "    # Optionally, add normalization, augmentation, etc.\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=0)),  # Pad to square so the entire card is visible\n",
    "    transforms.Resize(224),  # Resize the square image to 224×224 without cropping\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# show some sample images after the train_transform\n",
    "def show_sample_images(df, transform):\n",
    "    sample_df = df.sample(5)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for ax, (_, row) in zip(axes, sample_df.iterrows()):\n",
    "        img_path = row['filename']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transform(image)\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "print(\"\\nSample images after train_transform:\")\n",
    "show_sample_images(train_df, train_transform)\n",
    "\n",
    "# Custom dataset with cropping\n",
    "class CardDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        if ACTIVATE_CROPPING:\n",
    "            self.failed_crops = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['filename']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if ACTIVATE_CROPPING:\n",
    "            image_np = np.array(image)\n",
    "            cropped_np = crop_card(image_np)\n",
    "            if cropped_np is image_np:  # Cropping failed, log it\n",
    "                self.failed_crops.append(img_path)\n",
    "            image = Image.fromarray(cropped_np)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# print some sample cropped images\n",
    "def show_sample_crops(df, transform):\n",
    "    sample_df = df.sample(5)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for ax, (_, row) in zip(axes, sample_df.iterrows()):\n",
    "        img_path = row['filename']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        cropped_np = crop_card(image_np)\n",
    "        image = Image.fromarray(cropped_np)\n",
    "        if transform:\n",
    "            image = transform(image)\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if ACTIVATE_CROPPING:\n",
    "    show_sample_crops(train_df, train_transform)\n",
    "else:\n",
    "    print(\"Skipping cropping visualization.\")\n",
    "    # instead show some sample images\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for ax, (_, row) in zip(axes, train_df.sample(5).iterrows()):\n",
    "        img_path = row['filename']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = BATCH_SIZE  # Adjust based on GPU memory\n",
    "train_dataset = CardDataset(train_df, transform=train_transform)\n",
    "val_dataset = CardDataset(val_df, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Log failed crops\n",
    "if ACTIVATE_CROPPING:\n",
    "    print(f\"Training failed crops: {len(train_dataset.failed_crops)}\")\n",
    "    print(f\"Validation failed crops: {len(val_dataset.failed_crops)}\")\n",
    "\n",
    "# Build ResNet50 model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# model = models.resnet101(weights=models.ResNet101_Weights.DEFAULT)\n",
    "# model = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "# model = models.convnext_large(weights=models.ConvNeXt_Large_Weights.DEFAULT)\n",
    "# model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(DROPOUT_PROB),\n",
    "    nn.Linear(1024, len(le.classes_))\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze all layers except fc initially\n",
    "for name, param in model.named_parameters():\n",
    "    if 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Loss and optimizer\n",
    "if ACTIVATE_WEIGHTS_TENSOR:\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "# optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, weight_decay=1e-4)\n",
    "# AdamW Optimizer\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                        lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, min_lr=1e-6)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_INITIAL, eta_min=1e-6)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)  # Use .logits for ConvNeXt\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, phase='initial'):\n",
    "    best_val_loss = float('inf')\n",
    "    # patience = 7\n",
    "    patience_counter = 0\n",
    "    scaler = GradScaler()\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(f'{phase} Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f'best_model_{phase.lower()}.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "\n",
    "    return history\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Initial Training\n",
    "# -----------------------------\n",
    "history_initial = train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                              scheduler, num_epochs=EPOCHS_INITIAL, phase='Initial')\n",
    "\n",
    "# Load best model from initial phase\n",
    "model.load_state_dict(torch.load('best_model_initial.pth'))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Fine-tuning (Unfreeze more layers)\n",
    "# -----------------------------\n",
    "for name, param in model.named_parameters():\n",
    "    # Unfreeze layer3, layer4, and fc\n",
    "    if any([layer in name for layer in ['layer3', 'layer4', 'fc']]):\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Re-initialize the optimizer & scheduler for fine-tuning\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                        lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_FINE_TUNE, eta_min=1e-6)\n",
    "# Or use ReduceLROnPlateau again if you prefer.\n",
    "\n",
    "history_fine = train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                           scheduler, num_epochs=EPOCHS_FINE_TUNE, phase='Fine-tune')\n",
    "\n",
    "# Load best fine-tuned model\n",
    "model.load_state_dict(torch.load('best_model_fine-tune.pth'))\n",
    "\n",
    "# Visualize training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_initial['val_accuracy'] + history_fine['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history_initial['train_loss'] + history_fine['train_loss'], label='Train Loss')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_initial['val_loss'] + history_fine['val_loss'], label='Val Loss')\n",
    "plt.plot(history_initial['train_loss'] + history_fine['train_loss'], label='Train Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), 'card_grader_model.pth')\n",
    "\n",
    "# Prediction function\n",
    "def predict_grade(img_path, model, le, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image_np = np.array(image)\n",
    "    cropped_np = crop_card(image_np)\n",
    "    image = Image.fromarray(cropped_np)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return le.inverse_transform([predicted.item()])[0]\n",
    "\n",
    "# print overall model accuracy\n",
    "val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "print(f\"Overall Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = '../scrape/pictures/test.jpg'  # Replace with your test image\n",
    "predicted_grade = predict_grade(test_img_path, model, le, val_transform)\n",
    "print(f\"Predicted PSA grade: {predicted_grade}; Expected 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = '../scrape/pictures/cert_99449754.jpg'  # Replace with your test image\n",
    "predicted_grade = predict_grade(test_img_path, model, le, val_transform)\n",
    "print(f\"Predicted PSA grade: {predicted_grade}; Expected 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = '../scrape/pictures/cert_95743446.jpg'  # Replace with your test image\n",
    "predicted_grade = predict_grade(test_img_path, model, le, val_transform)\n",
    "print(f\"Predicted PSA grade: {predicted_grade}; Expected 6\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
