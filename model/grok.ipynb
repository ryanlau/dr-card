{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm  # For Vision Transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Configuration\n",
    "ACTIVATE_WEIGHTS_TENSOR = 0  # Enable class weights\n",
    "ACTIVATE_CROPPING = 0  # Enable cropping\n",
    "BATCH_SIZE = 32  # Suitable for ViT-Large with 384x384 inputs on H200\n",
    "EPOCHS = 100  # Single-phase training\n",
    "DROPOUT_PROB = 0.3\n",
    "LR = 1e-5  # Lower learning rate for ViT\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 10  # Increased patience for early stopping\n",
    "SPLIT_FRAC = 0.7\n",
    "\n",
    "# Set Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('../scrape/psa_sales_20250222_170248.csv')  # Replace with your CSV path\n",
    "image_dir = '../scrape/cropped'  # Replace with your image directory\n",
    "df['filename'] = df['certNumber'].apply(lambda x: os.path.join(image_dir, f\"cert_{x}.jpg\"))\n",
    "\n",
    "# Print Missing Images\n",
    "missing_images = len(df[df['filename'].apply(lambda x: not os.path.exists(x))])\n",
    "print(f\"Missing images: {missing_images}\")\n",
    "\n",
    "# Remove Non-Existing Images\n",
    "df = df[df['filename'].apply(os.path.exists)]\n",
    "\n",
    "# Split into Training and Validation Sets\n",
    "train_df = df.sample(frac=SPLIT_FRAC, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "# Encode Labels\n",
    "le = LabelEncoder()\n",
    "le.fit(df['grade'])\n",
    "train_df['label'] = le.transform(train_df['grade'])\n",
    "val_df['label'] = le.transform(val_df['grade'])\n",
    "\n",
    "# Check Class Distribution\n",
    "print(\"Unique grades in full dataset:\", df['grade'].unique())\n",
    "print(\"Number of unique grades in full dataset:\", df['grade'].nunique())\n",
    "\n",
    "grade_counts = df['grade'].value_counts().reset_index()\n",
    "grade_counts.columns = ['grade', 'count']\n",
    "grade_counts['percent'] = grade_counts['count'] / len(df) * 100\n",
    "print(grade_counts)\n",
    "\n",
    "# Compute Class Weights for Imbalance\n",
    "if ACTIVATE_WEIGHTS_TENSOR:\n",
    "    classes = np.unique(train_df['grade'])\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=train_df['grade'])\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    print(\"Class weights computed.\")\n",
    "\n",
    "# Define Cropping Functions\n",
    "def crop_card_for_light_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, otsu_grad = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(otsu_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    height, width = image.shape[:2]\n",
    "    image_area = height * width\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for contour in contours:\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.001 * peri, True)\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        area = w * h\n",
    "        if 0.48 * image_area <= area <= 0.6 * image_area:\n",
    "            return image[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "def crop_card_for_dark_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), -10)\n",
    "    adaptive_binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, 3)\n",
    "    edges = cv2.Canny(adaptive_binary, 100, 200)\n",
    "    binarized_grad = 255 - edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    open_binarized_grad = cv2.morphologyEx(binarized_grad, cv2.MORPH_OPEN, kernel)\n",
    "    contours, _ = cv2.findContours(open_binarized_grad, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    height, width = image.shape[:2]\n",
    "    image_area = height * width\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if 0.48 * image_area <= area <= 0.7 * image_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            return image[y:y+h, x:x+w]\n",
    "    return None\n",
    "\n",
    "def crop_card(image):\n",
    "    cropped = crop_card_for_light_image(image)\n",
    "    if cropped is not None:\n",
    "        return cropped\n",
    "    cropped = crop_card_for_dark_image(image)\n",
    "    if cropped is not None:\n",
    "        return cropped\n",
    "    return image  # Fallback to original if cropping fails\n",
    "\n",
    "def pad_to_square(image, fill=0, padding_mode=\"constant\"):\n",
    "    w, h = image.size\n",
    "    if w == h:\n",
    "        return image\n",
    "    max_wh = max(w, h)\n",
    "    pad_left = (max_wh - w) // 2\n",
    "    pad_top = (max_wh - h) // 2\n",
    "    pad_right = max_wh - w - pad_left\n",
    "    pad_bottom = max_wh - h - pad_top\n",
    "    padding = (pad_left, pad_top, pad_right, pad_bottom)\n",
    "    return transforms.Pad(padding, fill=fill, padding_mode=padding_mode)(image)\n",
    "\n",
    "# Define Enhanced Transforms with Augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=0)),\n",
    "    transforms.Resize(384),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: pad_to_square(img, fill=0)),\n",
    "    transforms.Resize(384),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Visualize Sample Images After Transform\n",
    "def show_sample_images(df, transform, title=\"Sample Images\"):\n",
    "    sample_df = df.sample(5)\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for ax, (_, row) in zip(axes, sample_df.iterrows()):\n",
    "        img_path = row['filename']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if ACTIVATE_CROPPING:\n",
    "            image_np = np.array(image)\n",
    "            cropped_np = crop_card(image_np)\n",
    "            image = Image.fromarray(cropped_np)\n",
    "        image = transform(image)\n",
    "        ax.imshow(image.permute(1, 2, 0).numpy() * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))\n",
    "        ax.axis('off')\n",
    "        ax.set_title(row['grade'])\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample images after train_transform:\")\n",
    "show_sample_images(train_df, train_transform, \"Training Samples After Transform\")\n",
    "\n",
    "# Custom Dataset\n",
    "class CardDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.failed_crops = [] if ACTIVATE_CROPPING else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['filename']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if ACTIVATE_CROPPING:\n",
    "            image_np = np.array(image)\n",
    "            cropped_np = crop_card(image_np)\n",
    "            if cropped_np is image_np:  # Cropping failed\n",
    "                self.failed_crops.append(img_path)\n",
    "            image = Image.fromarray(cropped_np)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create Datasets and Dataloaders\n",
    "train_dataset = CardDataset(train_df, transform=train_transform)\n",
    "val_dataset = CardDataset(val_df, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Log Failed Crops\n",
    "if ACTIVATE_CROPPING:\n",
    "    # Note: Failed crops are logged during dataset iteration\n",
    "    print(\"Failed crops will be logged after first epoch.\")\n",
    "\n",
    "# Load Vision Transformer Model\n",
    "model = timm.create_model('vit_large_patch16_384', pretrained=True, num_classes=len(le.classes_))\n",
    "model = model.to(device)\n",
    "\n",
    "# Set All Parameters to Require Gradients\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Loss Function with Class Weights and Label Smoothing\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor if ACTIVATE_WEIGHTS_TENSOR else None, label_smoothing=0.1)\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# Validation Function\n",
    "def validate(model, val_loader, criterion, use_tta=False):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if use_tta:\n",
    "                outputs = []\n",
    "                # Original\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    out = model(inputs)\n",
    "                outputs.append(out)\n",
    "                # Horizontal Flip\n",
    "                inputs_flipped = torch.flip(inputs, dims=[3])\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    out_flipped = model(inputs_flipped)\n",
    "                outputs.append(out_flipped)\n",
    "                # Average Predictions and Cast to Float32\n",
    "                outputs = torch.stack(outputs).mean(dim=0).float()\n",
    "            else:\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(inputs)\n",
    "                outputs = outputs.float()  # Cast to Float32\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Training Function with Early Stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    scaler = torch.amp.GradScaler('cuda')  # Updated API\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):  # Updated API\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.float(), labels)  # Cast to Float32\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, use_tta=False)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print('Early stopping')\n",
    "                break\n",
    "\n",
    "        # Log failed crops after first epoch\n",
    "        if epoch == 0 and ACTIVATE_CROPPING:\n",
    "            print(f\"Training failed crops: {len(train_dataset.failed_crops)}\")\n",
    "            print(f\"Validation failed crops: {len(val_dataset.failed_crops)}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Train the Model\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=EPOCHS)\n",
    "\n",
    "# Load Best Model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate with and without TTA\n",
    "val_loss, val_acc = validate(model, val_loader, criterion, use_tta=False)\n",
    "print(f\"Validation Accuracy without TTA: {val_acc:.4f}\")\n",
    "\n",
    "val_loss_tta, val_acc_tta = validate(model, val_loader, criterion, use_tta=True)\n",
    "print(f\"Validation Accuracy with TTA: {val_acc_tta:.4f}\")\n",
    "\n",
    "# Visualize Training History\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['val_accuracy'], label='Val Accuracy')\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.title('Model Accuracy and Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save Final Model\n",
    "torch.save(model.state_dict(), 'card_grader_model.pth')\n",
    "\n",
    "# Prediction Function with TTA\n",
    "def predict_grade(img_path, model, le, transform, use_tta=False):\n",
    "    model.eval()\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    if ACTIVATE_CROPPING:\n",
    "        image_np = np.array(image)\n",
    "        cropped_np = crop_card(image_np)\n",
    "        image = Image.fromarray(cropped_np)\n",
    "    if use_tta:\n",
    "        # Original\n",
    "        img_original = transform(image).unsqueeze(0).to(device)\n",
    "        # Horizontal Flip\n",
    "        img_flipped = transform(transforms.functional.hflip(image)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                output_original = model(img_original)\n",
    "                output_flipped = model(img_flipped)\n",
    "            outputs = (output_original + output_flipped) / 2\n",
    "    else:\n",
    "        img = transform(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(img)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    return le.inverse_transform([predicted.item()])[0]\n",
    "\n",
    "# Test Prediction\n",
    "sample_img_path = val_df['filename'].iloc[0]\n",
    "grade_pred = predict_grade(sample_img_path, model, le, val_transform, use_tta=True)\n",
    "print(f\"Predicted grade for sample image: {grade_pred}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
